{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainerBase(object):\n",
    "\n",
    "    def __init__(self, model_interface, data_interface):\n",
    "\n",
    "        self.model_interface = model_interface\n",
    "        self.data_interface = data_interface\n",
    "\n",
    "    def generate_counterfactuals(self):\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate_nearest_CF_neighbour(self):\n",
    "\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def plot_explanation(self):\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "class CounterfactualIG(ExplainerBase):\n",
    "\n",
    "    def __init__(self, model_interface, data_interface):\n",
    "\n",
    "        super().__init__(model_interface, data_interface)\n",
    "    \n",
    "    \n",
    "    def generate_nearest_CF_neighbour(self, query_instance):\n",
    "        #cf_pred = self.model_interface(query_instance)\n",
    "        #target = np.argmin(cf_pred.detach().numpy())\n",
    "        #dist = distance.squareform(distance.pdist(self.data_interface)) #distance between each data points w.r.t all other data points\n",
    "        #nearest_neighbours = np.argsort(dist, axis=1)  #number of closest points\n",
    "        #nearest_neighbours_arr = nearest_neighbours[inp_idx]\n",
    "        #for i in range(len(nearest_neighbours_arr)-1):\n",
    "        #    if np.round(self.model_interface(self.data_interface[nearest_neighbours_arr[i]])[target].detach().numpy()) != np.round(self.model_interface(self.data_interface[inp_idx])[target].detach().numpy()): #convert to numpy from tensor\n",
    "        #        closest_instance = data[nearest_neighbours_arr[i]]  \n",
    "        \n",
    "        \n",
    "        return print(\"This function is not yet implemented in the non-client side version of this method used in the paper \\n simple adaptation of the code in the source file are necessary to make this work in the general case.\")\n",
    "        \n",
    "    \n",
    "    def generate_counterfactuals(self, query_instance, counterfactual, target = 0.5, _K=500, decision_boundary_proba=0.5):\n",
    "       \n",
    "        \"\"\" \n",
    "        \n",
    "        Requires both query_instance and counterfactual to be tensors in an array - working to fix this:\n",
    "        \n",
    "        Currently, the input must be: [input_tensor[a:a+1]] and [counterfactual_tensor] associated with [input_tensor[a:a+1]]\n",
    "        \n",
    "        \"\"\"\n",
    "        self._K = _K #number of steps in the Riemann Approximation\n",
    "        #query_instance = torch.FloatTensor(query_instance) \n",
    "        #counterfactual = torch.FloatTensor(counterfactual)\n",
    "\n",
    "        # k/m in the formula\n",
    "        alphas = torch.linspace(0, 1, _K).tolist()\n",
    "    \n",
    "        # direct path from baseline to input. shape : ([n_steps, n_features], )\n",
    "        scaled_features = tuple(\n",
    "                torch.cat(\n",
    "                    [baseline + alpha * (input - baseline) for alpha in alphas], dim=0\n",
    "                ).requires_grad_()\n",
    "                for input, baseline in zip(counterfactual, query_instance)\n",
    "            )\n",
    "    \n",
    "        # predictions at every step. shape : [n_steps, 1]\n",
    "        cf_pred = self.model_interface(counterfactual[0])\n",
    "        target = np.argmax(cf_pred.detach().numpy()) #index returned by arg max of the greatest pred probability aka. if 0 is highest then pred = 0\n",
    "        preds = self.model_interface(scaled_features[0])[:, target] \n",
    "    \n",
    "        cf_exp = scaled_features\n",
    "    \n",
    "        index = min(find_indices(self.model_interface(cf_exp[0])[:,target], lambda e: e >= decision_boundary_proba))\n",
    "    \n",
    "        new_feature = scaled_features[0][index]\n",
    "    \n",
    "        new_scaled_features = tuple(\n",
    "            torch.cat(\n",
    "                [baseline + alpha * (input - baseline) for alpha in alphas], dim=0\n",
    "            ).requires_grad_()\n",
    "            for input, baseline in zip(new_feature, query_instance)\n",
    "        )\n",
    "    \n",
    "        preds2 = self.model_interface(new_scaled_features[0])[:,target]\n",
    "    \n",
    "        # gradients of predictions wrt input features. shape : [n_steps, n_features]\n",
    "    \n",
    "        #grads = grad(outputs=torch.unbind(preds), inputs=scaled_features)\n",
    "        grads = grad(outputs=torch.unbind(preds2), inputs=new_scaled_features)\n",
    "    \n",
    "        explanation_a = grads[0].mean(0) #get the mean gradient between both points\n",
    "        \n",
    "        explanation = explanation_a*(new_feature[0].detach().numpy() - query_instance[0].detach().numpy())\n",
    "            \n",
    "        return explanation\n",
    "    \n",
    "    def find_indices(lst, condition):  #used to find the index of the minimum value over decision bounds for target\n",
    "        return [i for i, elem in enumerate(lst) if condition(elem)] \n",
    "\n",
    "    \n",
    "    def plot_explanation(self, explanation_array, query_instance, counterfactual):\n",
    "        \"\"\" \n",
    "        \n",
    "        explanation_array = explanation provided by generate_counterfactuals()\n",
    "        \n",
    "        query_instance = use the same instance as input into generate_counterfactuals() but as a tensor,\n",
    "        thus written as input_tensor[a:a+1] not [input_tensor[a:a+1]]\n",
    "        \n",
    "        counterfactual_instance = the same counterfactual input into generate_counterfactuals() but as a tensor,\n",
    "        thus written as counterfactual_tensor not [counterfactual_tensor]\n",
    "        \n",
    "        \"\"\"\n",
    "        explanation = explanation_array.detach().numpy()\n",
    "        increase_or_decrease_for_counterfactual = query_instance.detach().numpy() - counterfactual.detach().numpy()\n",
    "        feature_names = self.data_interface.columns.tolist()\n",
    "        \n",
    "        \n",
    "        result_increase_cf = [np.sign(val) for val in increase_or_decrease_for_counterfactual]\n",
    "        third_array_values = ['Increased Value' if val < 0 else 'Decreased Value' if val > 0 else 'No Change' for val in result_increase_cf]\n",
    "        \n",
    "        \n",
    "        font = {'family':'normal',\n",
    "               'weight':'bold',\n",
    "               'size': 12}\n",
    "        plt.rc('font', **font)\n",
    "        # Append each value from third_array_values to the corresponding feature name\n",
    "        # Format: feature_name (value)\n",
    "        for idx, value in enumerate(third_array_values):\n",
    "            feature_names[idx] += f' ({value})'\n",
    "\n",
    "        # Create a figure and axis\n",
    "        %matplotlib qt\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        bars =[]\n",
    "        # Plot the horizontal bars\n",
    "        bars = []\n",
    "        for idx, value in enumerate(explanation):\n",
    "            color = 'red' if value < 0 else 'green'\n",
    "            bar = ax.barh(feature_names[idx], value, color=color)\n",
    "            bars.append(bar)\n",
    "\n",
    "        # Attach data as annotations to each bar\n",
    "            mplcursors.cursor(bar).connect(\n",
    "                \"add\", lambda sel, idx=idx: sel.annotation.set_text(\n",
    "                    f'Old Feature Value: {input_tensor[2:3].detach().numpy()[0][idx]}, New Feature Value: {nearest_neighbour_list[2].detach().numpy()[idx]}'\n",
    "                )\n",
    "            )\n",
    "    \n",
    "        ax.set_xlabel('Attribution Values')    \n",
    "    \n",
    "        #def on_hover(sel):\n",
    "        #    bar_index = sel.artist.get_label()\n",
    "        #    val1 = input_tensor[2:3].detach().numpy()[0][bar_index]\n",
    "        #    val2 = nearest_neighbour_list[2].detach().numpy()[bar_index]\n",
    "        #    sel.annotation.set_text(f'Old Feature Value: {val1}\\n New Feature Value: {val2}')\n",
    "        #    sel.annotation.get_bbox_patch().set(fc=\"white\", alpha=0.8)\n",
    "\n",
    "        # Add the interactivity using mplcursors\n",
    "        cursor = mplcursors.cursor(bars, hover=True)\n",
    "        #cursor.connect(\"add\", on_hover)\n",
    "        # Set the x-axis label\n",
    "        plt.title(\"Counterfactual Feature Attribution\")\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
